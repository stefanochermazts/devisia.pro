---
import Layout from '../../layouts/Layout.astro';
import Button from '../../components/ui/Button.astro';
import Radio from '../../components/ui/Radio.astro';
import Card from '../../components/ui/Card.astro';
import Badge from '../../components/ui/Badge.astro';

const questions = [
  {
    id: 'data-sensitivity',
    name: 'dataSensitivity',
    label: 'Sensibilità dei dati',
    description: 'Valuta quanto sono critiche le informazioni elaborate dal sistema AI.',
    options: [
      { value: '0', label: 'Nessun dato personale', description: 'Dati pubblici o sintetici senza alcun riferimento a individui identificabili.' },
      { value: '1', label: 'Dati personali (non sensibili)', description: 'Informazioni comuni come nomi, email aziendali o preferenze di navigazione.' },
      { value: '2', label: 'Dati sensibili (salute, finanza, minori, ecc.)', description: 'Informazioni protette che richiedono tutele massime e conformità rigorosa.' },
    ],
  },
  {
    id: 'user-input',
    name: 'userInput',
    label: 'Input utente',
    description: 'Il volume e il tipo di dati che gli utenti caricano o scrivono nei prompt.',
    options: [
      { value: '0', label: 'Solo prompt brevi', description: 'Interazioni testuali semplici e limitate a poche righe.' },
      { value: '1', label: 'Prompt + documenti/frammenti di testo', description: 'Invio di testi estesi o porzioni di documenti per analisi o sintesi.' },
      { value: '2', label: 'Upload di file', description: 'Caricamento di file interi (PDF, immagini) che possono contenere dati non filtrati.' },
    ],
  },
  {
    id: 'output-impact',
    name: 'outputImpact',
    label: 'Impatto dell\'output',
    description: 'Quanto peso e quali conseguenze hanno i risultati generati dall\'AI nel mondo reale.',
    options: [
      { value: '0', label: 'Solo informativo', description: 'L\'output è usato solo per consultazione o supporto creativo non critico.' },
      { value: '1', label: 'Assiste nelle decisioni', description: 'L\'output guida scelte umane in ambiti professionali o processi operativi.' },
      { value: '2', label: 'Azioni automatizzate (scrive/esegue modifiche)', description: 'L\'AI esegue modifiche a database, scrive codice o invia comunicazioni in autonomia.' },
    ],
  },
  {
    id: 'human-oversight',
    name: 'humanOversight',
    label: 'Supervisione umana',
    description: 'Il livello di controllo e validazione umana prima che l\'output dell\'AI venga utilizzato.',
    options: [
      { value: '0', label: 'Sempre revisionato da umani', description: 'Ogni singolo output viene verificato da una persona prima di qualunque utilizzo.' },
      { value: '1', label: 'A volte revisionato', description: 'Revisione parziale, a campione o limitata solo ad alcuni casi d\'uso.' },
      { value: '2', label: 'Nessuna revisione / completamente automatizzato', description: 'L\'AI opera in autonomia senza filtri o approvazioni umane dirette.' },
    ],
  },
  {
    id: 'access-control',
    name: 'accessControl',
    label: 'Controllo accessi',
    description: 'Chi sono i destinatari o gli utenti che interagiscono con le funzionalità AI.',
    options: [
      { value: '0', label: 'Singolo team', description: 'Uso interno limitato a un gruppo ristretto, fidato e formato.' },
      { value: '1', label: 'Ruoli/tenant multipli', description: 'Uso esteso a diversi reparti aziendali o gruppi di utenti segregati.' },
      { value: '2', label: 'Utenti/clienti esterni', description: 'L\'AI è esposta a utenti finali o clienti fuori dal controllo diretto dell\'organizzazione.' },
    ],
  },
  {
    id: 'logging-needs',
    name: 'loggingNeeds',
    label: 'Esigenze di logging',
    description: 'Il livello di tracciabilità necessario per monitorare le interazioni e garantire la compliance.',
    options: [
      { value: '0', label: 'Log minimi', description: 'È sufficiente monitorare lo stato del sistema e gli errori tecnici generali.' },
      { value: '1', label: 'Log standard', description: 'Tracciamento di base su chi usa il sistema, quando e con quali volumi.' },
      { value: '2', label: 'Richiede audit trail', description: 'Registrazione immutabile di ogni singola interazione per fini legali o normativi.' },
    ],
  },
  {
    id: 'model-usage',
    name: 'modelUsage',
    label: 'Utilizzo del modello',
    description: 'In che modo l\'AI interagisce con altri sistemi o esegue compiti tecnici.',
    options: [
      { value: '0', label: 'Solo chiamate API', description: 'Il modello riceve input e restituisce testo, senza interagire con altre risorse.' },
      { value: '1', label: 'API + strumenti/agenti', description: 'L\'AI può invocare strumenti esterni (es. calcolatrici, ricerche) per arricchire l\'output.' },
      { value: '2', label: 'Agenti che eseguono workflow', description: 'L\'AI orchestra processi complessi chiamando più funzioni in sequenza autonoma.' },
    ],
  },
  {
    id: 'retention',
    name: 'retention',
    label: 'Conservazione',
    description: 'Per quanto tempo i dati di input e output rimangono memorizzati nei sistemi.',
    options: [
      { value: '0', label: 'Nessuna conservazione', description: 'I dati vengono eliminati immediatamente dopo l\'elaborazione della risposta.' },
      { value: '1', label: 'Conservazione breve (<= 30 giorni)', description: 'Memorizzazione limitata al tempo necessario per la sessione o debug immediato.' },
      { value: '2', label: 'Conservazione lunga (> 30 giorni)', description: 'Dati archiviati per analisi storiche, miglioramento modelli o obblighi contrattuali.' },
    ],
  },
];

const safeguards = [
  {
    id: 'data-minimization',
    label: 'Minimizzazione e redazione dei dati (PII)',
    description: 'Rimuovi o maschera informazioni personali identificabili (PII) prima dell\'invio ai modelli AI. Applica tecniche di redazione automatica per nomi, email, numeri di telefono e altri dati sensibili, riducendo il rischio di esposizione non autorizzata.',
    triggers: ['dataSensitivity:1', 'dataSensitivity:2', 'userInput:1', 'userInput:2'],
  },
  {
    id: 'retention-policy',
    label: 'Politica di conservazione rigorosa',
    description: 'Definisci tempi massimi di conservazione per dati e log, con eliminazione automatica al termine del periodo. Limita la conservazione solo ai dati strettamente necessari per il funzionamento del sistema, riducendo la superficie di attacco nel tempo.',
    triggers: ['retention:1', 'retention:2', 'dataSensitivity:2'],
  },
  {
    id: 'rbac',
    label: 'Controllo accessi basato su ruoli (RBAC)',
    description: 'Implementa un sistema di permessi granulare che limita l\'accesso alle funzionalità AI in base al ruolo dell\'utente. Assicura che solo personale autorizzato possa accedere a dati sensibili o configurare parametri critici del sistema.',
    triggers: ['accessControl:1', 'accessControl:2', 'dataSensitivity:1', 'dataSensitivity:2'],
  },
  {
    id: 'audit-logging',
    label: 'Audit logging (a livello di evento)',
    description: 'Registra tutti gli eventi significativi del sistema AI: chiamate API, accessi ai dati, modifiche di configurazione, errori. Mantieni log immutabili e ricercabili per analisi forensi e compliance con normative come GDPR o SOC 2.',
    triggers: ['loggingNeeds:2', 'outputImpact:2', 'accessControl:2'],
  },
  {
    id: 'prompt-filtering',
    label: 'Filtraggio prompt/output e controlli policy',
    description: 'Valida input e output del modello AI per bloccare contenuti inappropriati, prompt injection, o risposte che violano policy aziendali. Implementa filtri basati su regex, liste nere, o modelli di classificazione per garantire conformità.',
    triggers: ['userInput:1', 'userInput:2', 'outputImpact:1', 'outputImpact:2'],
  },
  {
    id: 'human-review',
    label: 'Revisione human-in-the-loop per output ad alto impatto',
    description: 'Richiedi approvazione umana prima di eseguire azioni critiche generate dall\'AI (scrittura di dati, invio email, modifiche a configurazioni). Implementa workflow di approvazione con notifiche e interfacce di revisione per decisioni ad alto rischio.',
    triggers: ['outputImpact:2', 'humanOversight:1', 'humanOversight:2'],
  },
  {
    id: 'fallback',
    label: 'Strategia di fallback (modalità degradata)',
    description: 'Definisci comportamenti alternativi quando l\'AI non è disponibile o restituisce errori. Implementa modalità degradate che permettono al sistema di continuare a funzionare con funzionalità ridotte, evitando interruzioni complete del servizio.',
    triggers: ['outputImpact:1', 'outputImpact:2', 'modelUsage:1', 'modelUsage:2'],
  },
  {
    id: 'observability',
    label: 'Osservabilità (latenza, errori, costi, rate limits)',
    description: 'Monitora metriche chiave del sistema AI: tempi di risposta, tasso di errore, costi per chiamata, utilizzo di rate limits. Configura alerting per anomalie e dashboard per visualizzare trend, permettendo ottimizzazione proattiva e identificazione precoce di problemi.',
    triggers: ['modelUsage:1', 'modelUsage:2', 'outputImpact:1', 'outputImpact:2'],
  },
  {
    id: 'vendor-governance',
    label: 'Governance vendor/modello (versioning, tracciamento modifiche)',
    description: 'Mantieni traccia delle versioni dei modelli AI utilizzati e delle modifiche alle API dei vendor. Documenta cambiamenti, test di regressione, e impatti su performance. Implementa strategie di versioning che permettono rollback in caso di problemi.',
    triggers: ['modelUsage:1', 'modelUsage:2', 'dataSensitivity:1', 'dataSensitivity:2'],
  },
  {
    id: 'tool-allowlist',
    label: 'Allow-list per tool calling',
    description: 'Limita gli strumenti che gli agenti AI possono utilizzare a una lista esplicita e approvata. Blocca chiamate a tool non autorizzati, prevenendo esecuzione di codice arbitrario o accesso non autorizzato a risorse di sistema. Valida ogni chiamata tool prima dell\'esecuzione.',
    triggers: ['modelUsage:2'],
  },
];
---

<Layout title="Checklist rischio AI e privacy" description="Una valutazione pratica per stimare il livello di rischio e le misure di sicurezza consigliate per software abilitato all'AI." lang="it">
  <div class="ds-container ds-stack" data-gap="lg" style="container-type: inline-size; margin-top: var(--ds-space-8)">
    <header class="ds-stack" data-gap="sm">
      <h1 style="margin: 0">AI Risk & Privacy Checklist</h1>
      <p class="ds-muted" style="max-width: 65ch">
        Una valutazione pratica per stimare il livello di rischio e le misure di sicurezza consigliate per software abilitato all'AI.
      </p>
      <p class="ds-muted" style="font-size: var(--ds-text-xs); margin: 0">
        Nessun upload. Nessun storage. Le tue risposte rimangono nel browser.
      </p>
    </header>

    <form id="checklist-form" class="ds-stack" data-gap="lg">
      {questions.map((q, idx) => (
        <Card>
          <div class="ds-card__body ds-stack" data-gap="sm">
            <div class="ds-stack" data-gap="xs">
              <label class="ds-label" for={`${q.id}-0`}>
                {idx + 1}. {q.label}
              </label>
              {q.description && (
                <p class="ds-muted" style="margin: 0; font-size: var(--ds-text-sm)">
                  {q.description}
                </p>
              )}
            </div>
            <div class="ds-stack" data-gap="sm" style="margin-top: var(--ds-space-2)">
              {q.options.map((opt, optIdx) => (
                <div class="ds-stack" data-gap="xs">
                  <Radio
                    id={`${q.id}-${optIdx}`}
                    name={q.name}
                    label={opt.label}
                    value={opt.value}
                    checked={optIdx === 0}
                  />
                  {opt.description && (
                    <p class="ds-muted" style="margin: 0 0 0 calc(18px + 0.75rem); font-size: var(--ds-text-xs); line-height: var(--ds-leading-relaxed)">
                      {opt.description}
                    </p>
                  )}
                </div>
              ))}
            </div>
            {q.id === 'user-input' && (
              <div id="file-upload-warning" class="ds-alert" data-tone="warning" style="display: none; margin-top: var(--ds-space-2)">
                <p style="margin: 0; font-size: var(--ds-text-sm)">
                  <strong>Nota:</strong> Gli upload di file non sono supportati in questa demo. Considera la minimizzazione e redazione dei dati per implementazioni in produzione.
                </p>
              </div>
            )}
          </div>
        </Card>
      ))}

      <div class="ds-cluster">
        <Button type="submit" variant="primary">
          Genera raccomandazioni
        </Button>
      </div>
    </form>

    <div id="results-panel" class="ds-stack" data-gap="lg" style="display: none">
      <Card>
        <div class="ds-card__body ds-stack" data-gap="md">
          <div class="ds-cluster">
            <Badge id="risk-badge" tone="neutral">Basso</Badge>
          </div>
          <p id="risk-explanation" class="ds-muted" style="margin: 0"></p>
        </div>
      </Card>

      <div class="ds-stack" data-gap="md">
        <h3 style="margin: 0; font-size: var(--ds-text-lg); font-weight: 600">Misure di sicurezza consigliate</h3>
        <div id="safeguards-list" class="ds-stack" data-gap="md">
          <!-- Populated by JS -->
        </div>
      </div>
    </div>

    <footer class="ds-stack" data-gap="xs" style="margin-top: var(--ds-space-8); padding-top: var(--ds-space-6); border-top: var(--ds-border-1) solid var(--ds-color-border)">
      <p class="ds-muted" style="font-size: var(--ds-text-xs); margin: 0">
        Questa checklist è un punto di partenza, non un consiglio legale.
      </p>
    </footer>
  </div>

  <script>
    const form = document.getElementById('checklist-form');
    const resultsPanel = document.getElementById('results-panel');
    const riskBadge = document.getElementById('risk-badge');
    const riskExplanation = document.getElementById('risk-explanation');
    const safeguardsList = document.getElementById('safeguards-list');
    const fileUploadWarning = document.getElementById('file-upload-warning');

    // Questions data (mirrored from Astro frontmatter)
    const questions = [
      { name: 'dataSensitivity' },
      { name: 'userInput' },
      { name: 'outputImpact' },
      { name: 'humanOversight' },
      { name: 'accessControl' },
      { name: 'loggingNeeds' },
      { name: 'modelUsage' },
      { name: 'retention' },
    ];

    // Safeguards data (mirrored from Astro frontmatter)
    const safeguards = [
      {
        id: 'data-minimization',
        label: 'Minimizzazione e redazione dei dati (PII)',
        description: 'Rimuovi o maschera informazioni personali identificabili (PII) prima dell\'invio ai modelli AI. Applica tecniche di redazione automatica per nomi, email, numeri di telefono e altri dati sensibili, riducendo il rischio di esposizione non autorizzata.',
        triggers: ['dataSensitivity:1', 'dataSensitivity:2', 'userInput:1', 'userInput:2'],
      },
      {
        id: 'retention-policy',
        label: 'Politica di conservazione rigorosa',
        description: 'Definisci tempi massimi di conservazione per dati e log, con eliminazione automatica al termine del periodo. Limita la conservazione solo ai dati strettamente necessari per il funzionamento del sistema, riducendo la superficie di attacco nel tempo.',
        triggers: ['retention:1', 'retention:2', 'dataSensitivity:2'],
      },
      {
        id: 'rbac',
        label: 'Controllo accessi basato su ruoli (RBAC)',
        description: 'Implementa un sistema di permessi granulare che limita l\'accesso alle funzionalità AI in base al ruolo dell\'utente. Assicura che solo personale autorizzato possa accedere a dati sensibili o configurare parametri critici del sistema.',
        triggers: ['accessControl:1', 'accessControl:2', 'dataSensitivity:1', 'dataSensitivity:2'],
      },
      {
        id: 'audit-logging',
        label: 'Audit logging (a livello di evento)',
        description: 'Registra tutti gli eventi significativi del sistema AI: chiamate API, accessi ai dati, modifiche di configurazione, errori. Mantieni log immutabili e ricercabili per analisi forensi e compliance con normative come GDPR o SOC 2.',
        triggers: ['loggingNeeds:2', 'outputImpact:2', 'accessControl:2'],
      },
      {
        id: 'prompt-filtering',
        label: 'Filtraggio prompt/output e controlli policy',
        description: 'Valida input e output del modello AI per bloccare contenuti inappropriati, prompt injection, o risposte che violano policy aziendali. Implementa filtri basati su regex, liste nere, o modelli di classificazione per garantire conformità.',
        triggers: ['userInput:1', 'userInput:2', 'outputImpact:1', 'outputImpact:2'],
      },
      {
        id: 'human-review',
        label: 'Revisione human-in-the-loop per output ad alto impatto',
        description: 'Richiedi approvazione umana prima di eseguire azioni critiche generate dall\'AI (scrittura di dati, invio email, modifiche a configurazioni). Implementa workflow di approvazione con notifiche e interfacce di revisione per decisioni ad alto rischio.',
        triggers: ['outputImpact:2', 'humanOversight:1', 'humanOversight:2'],
      },
      {
        id: 'fallback',
        label: 'Strategia di fallback (modalità degradata)',
        description: 'Definisci comportamenti alternativi quando l\'AI non è disponibile o restituisce errori. Implementa modalità degradate che permettono al sistema di continuare a funzionare con funzionalità ridotte, evitando interruzioni complete del servizio.',
        triggers: ['outputImpact:1', 'outputImpact:2', 'modelUsage:1', 'modelUsage:2'],
      },
      {
        id: 'observability',
        label: 'Osservabilità (latenza, errori, costi, rate limits)',
        description: 'Monitora metriche chiave del sistema AI: tempi di risposta, tasso di errore, costi per chiamata, utilizzo di rate limits. Configura alerting per anomalie e dashboard per visualizzare trend, permettendo ottimizzazione proattiva e identificazione precoce di problemi.',
        triggers: ['modelUsage:1', 'modelUsage:2', 'outputImpact:1', 'outputImpact:2'],
      },
      {
        id: 'vendor-governance',
        label: 'Governance vendor/modello (versioning, tracciamento modifiche)',
        description: 'Mantieni traccia delle versioni dei modelli AI utilizzati e delle modifiche alle API dei vendor. Documenta cambiamenti, test di regressione, e impatti su performance. Implementa strategie di versioning che permettono rollback in caso di problemi.',
        triggers: ['modelUsage:1', 'modelUsage:2', 'dataSensitivity:1', 'dataSensitivity:2'],
      },
      {
        id: 'tool-allowlist',
        label: 'Allow-list per tool calling',
        description: 'Limita gli strumenti che gli agenti AI possono utilizzare a una lista esplicita e approvata. Blocca chiamate a tool non autorizzati, prevenendo esecuzione di codice arbitrario o accesso non autorizzato a risorse di sistema. Valida ogni chiamata tool prima dell\'esecuzione.',
        triggers: ['modelUsage:2'],
      },
    ];

    // Show warning for file uploads
    const userInputRadios = document.querySelectorAll('input[name="userInput"]');
    userInputRadios.forEach((radio) => {
      radio.addEventListener('change', () => {
        if (radio.value === '2') {
          fileUploadWarning.style.display = 'block';
        } else {
          fileUploadWarning.style.display = 'none';
        }
      });
    });

    // Scoring function
    function calculateScore(formData) {
      let score = 0;
      questions.forEach((q) => {
        const value = formData.get(q.name);
        if (value !== null) {
          score += parseInt(value, 10);
        }
      });
      return score;
    }

    // Determine risk level
    function getRiskLevel(score) {
      if (score <= 5) return { level: 'Basso', tone: 'neutral' };
      if (score <= 10) return { level: 'Medio', tone: 'accent' };
      return { level: 'Alto', tone: 'accent' };
    }

    // Get risk explanation
    function getRiskExplanation(score, riskLevel) {
      if (riskLevel === 'Basso') {
        return 'La tua implementazione AI ha fattori di rischio minimi. Misure di sicurezza di base dovrebbero essere sufficienti per la maggior parte dei casi d\'uso.';
      }
      if (riskLevel === 'Medio') {
        return 'La tua implementazione AI ha fattori di rischio moderati. Implementa misure di sicurezza mirate basate sulle tue risposte specifiche.';
      }
      return 'La tua implementazione AI ha fattori di rischio significativi. Implementa misure di sicurezza complete e considera misure di governance aggiuntive.';
    }

    // Get relevant safeguards
    function getRelevantSafeguards(formData, score) {
      const answers = {};
      questions.forEach((q) => {
        answers[q.name] = formData.get(q.name);
      });

      const answerKey = (name, value) => `${name}:${value}`;
      const relevant = safeguards.filter((safeguard) => {
        return safeguard.triggers.some((trigger) => {
          const [name, value] = trigger.split(':');
          return answers[name] === value;
        });
      });

      // Always include observability for medium+ risk
      if (score > 5) {
        const obs = safeguards.find((s) => s.id === 'observability');
        if (obs && !relevant.find((s) => s.id === 'observability')) {
          relevant.push(obs);
        }
      }

      // Always include data minimization for sensitive data
      if (answers.dataSensitivity === '1' || answers.dataSensitivity === '2') {
        const dm = safeguards.find((s) => s.id === 'data-minimization');
        if (dm && !relevant.find((s) => s.id === 'data-minimization')) {
          relevant.unshift(dm);
        }
      }

      // Sort by priority (data minimization first, then others)
      return relevant.sort((a, b) => {
        if (a.id === 'data-minimization') return -1;
        if (b.id === 'data-minimization') return 1;
        return 0;
      });
    }

    // Handle form submission
    form.addEventListener('submit', (e) => {
      e.preventDefault();
      const formData = new FormData(form);
      const score = calculateScore(formData);
      const { level, tone } = getRiskLevel(score);
      const explanation = getRiskExplanation(score, level);
      const relevantSafeguards = getRelevantSafeguards(formData, score);

      // Update UI
      riskBadge.textContent = level;
      riskBadge.setAttribute('data-tone', tone);
      riskExplanation.textContent = explanation;
      safeguardsList.innerHTML = relevantSafeguards
        .map(
          (s) => `
        <div class="ds-card">
          <div class="ds-card__body ds-stack" data-gap="sm">
            <h3 style="margin: 0; font-weight: 600; font-size: var(--ds-text-md)">${s.label}</h3>
            <p style="margin: 0; font-size: var(--ds-text-sm); color: var(--ds-color-text-muted); line-height: var(--ds-leading-relaxed)">${s.description}</p>
          </div>
        </div>
      `
        )
        .join('');

      // Show results
      resultsPanel.style.display = 'block';
      resultsPanel.scrollIntoView({ behavior: 'smooth', block: 'start' });
    });
  </script>
</Layout>
